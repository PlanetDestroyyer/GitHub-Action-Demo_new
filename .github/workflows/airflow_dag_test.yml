name: Airflow DAG CI/CD

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

jobs:
  airflow_dag_job:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v2

    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: 3.8  # Adjust this to your Python version if necessary

    - name: Set up AIRFLOW_HOME
      run: |
        export AIRFLOW_HOME=$(pwd)/airflow_home
        echo "AIRFLOW_HOME=$AIRFLOW_HOME" >> $GITHUB_ENV

    - name: Install dependencies
      run: |
        python -m venv venv
        source venv/bin/activate
        pip install apache-airflow
        pip install pandas numpy scikit-learn mlflow joblib

    - name: Initialize Airflow database
      run: |
        source venv/bin/activate
        airflow db init

    - name: Copy DAGs to Airflow DAGs folder
      run: |
        mkdir -p $AIRFLOW_HOME/dags
        cp dags/*.py $AIRFLOW_HOME/dags/

    - name: Copy dataset to the correct location
      run: |
        cp data/LoanApprovalPrediction.csv $AIRFLOW_HOME/LoanApprovalPrediction.csv

    - name: Start Airflow Webserver
      run: |
        source venv/bin/activate
        airflow webserver -p 8080 &
        sleep 10  # Allow the webserver to start properly

    - name: Start Airflow Scheduler
      run: |
        source venv/bin/activate
        airflow scheduler &
        sleep 20  # Allow the scheduler to start and load DAGs

    - name: List all available DAGs
      run: |
        source venv/bin/activate
        airflow dags list

    - name: Trigger Airflow DAG
      run: |
        source venv/bin/activate
        airflow dags trigger loan_approval_prediction_new

    - name: Collect and store logs
      run: |
        mkdir -p logs
        cp $AIRFLOW_HOME/logs/* logs/
      if: failure()
      
    - name: Upload logs as artifact
      uses: actions/upload-artifact@v2
      with:
        name: airflow-logs
        path: logs/
